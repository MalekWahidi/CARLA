Using cache found in /home/malek/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/20:   0%|                                                                            | 0/2998 [00:00<?, ?it/s]
=====================Training=====================
================Model Architecture================
Vision Backbone: dinov2
Pretrained: True
NCP: [384, 40, 3]
=============Training Hyperparameters=============
Epochs: 20
Learning rate (NCP): 0.001
Batch size: 4
Sequence length: 10
==================Hardware Specs==================
Device: GPU
Name: NVIDIA GeForce RTX 4060 Laptop GPU
Memory: 7.75 GB
=================Dataset Details==================
Dataset: town01_1
Size: 12000 frames
Num Workers: 19


























Epoch 1 - Loss: 0.064142:  10%|█████                                               | 289/2998 [01:01<04:48,  9.37it/s]Traceback (most recent call last):
  File "/home/malek/Documents/CARLA/train.py", line 229, in <module>
    train(perception_model, ncp_model, loss_fn, optimizer, dataloader, config['epochs'], checkpoint_path, pretrained, device)
  File "/home/malek/Documents/CARLA/train.py", line 83, in train
    loss.backward()
  File "/home/malek/anaconda3/envs/carla/lib/python3.8/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/home/malek/anaconda3/envs/carla/lib/python3.8/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt