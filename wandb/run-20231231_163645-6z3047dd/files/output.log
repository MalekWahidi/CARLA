Using cache found in /home/malek/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/20:   0%|                                                                            | 0/2998 [00:00<?, ?it/s]
=====================Training=====================
================Model Architecture================
Vision Backbone: dinov2
Pretrained: True
NCP: [384, 20, 3]
=============Training Hyperparameters=============
Epochs: 20
Learning rate (NCP): 0.001
Batch size: 4
Sequence length: 10
==================Hardware Specs==================
Device: GPU
Name: NVIDIA GeForce RTX 4060 Laptop GPU
Memory: 7.75 GB
=================Dataset Details==================
Dataset: town01_1














Epoch 1 - Loss: 0.106677:   4%|█▉                                                  | 112/2998 [00:38<05:24,  8.90it/s]Traceback (most recent call last):
  File "/home/malek/Documents/CARLA/train.py", line 214, in <module>
    train(perception_model, ncp_model, loss_fn, optimizer, dataloader, config['epochs'], checkpoint_path, pretrained, device)
  File "/home/malek/Documents/CARLA/train.py", line 82, in train
    loss.backward()
  File "/home/malek/anaconda3/envs/carla/lib/python3.8/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/home/malek/anaconda3/envs/carla/lib/python3.8/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt